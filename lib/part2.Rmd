---
title: 'Project1_zg2245 part2'
runtime: shiny
output:
  html_document: default
  html_notebook: default
---

Let's focus on the change of vocabulary in in these speeches.
    
    Firstly, personal pronouns. The usage of "I" is high at first few decades after establishing the country. However, "we" became more and more popular and dominated the speeches after word war II. This is reasonable as "we" includes both the speaker and the listeners. The use of "we" and "us" shows clearly that the speaker is on the side of his audience and therefore shortens the psychological distance between the speaker and the audience, thus arouses the audience's affirmative feelings and sympathetic responses.

    Secondly, key words of the speeches. At the founding of the early, the theme of speeches concerned to daily subject like happiness, virtuous, mind, pleasing. The second period, from 1817 to 1865, key words were related to politics and constitution, like union, powers, rights. After the civil war, the speeches paid more attention on economic and tax, key words were business, law, citizenship and so on. When it comes to modern times(1993 till now), the speeches became more ideological, key words were world, freedom, democracy etc.
    This can be explained with the certain political and economic environment. For example, the word "freedom" was first mentioned by Thomas Jefferson only combined in "freedom of religion", "freedom of press", "freedom of science". After the cold war, collocation is totally different, like "flam of freedom spreading throughout all the world"(William J. Clinton), "America's faith in freedom and democracy"(George Bush). Clearly, with the development of encomic, politician has to pay more attention on ideological subject since material life is satisfied.
    Another example is the replacement of "states" by "world". Until the 27th president William Taft, the usage of word "states" was relatively high. On the other hand, the frequence of word "world" keeps high since the 29th president Warren Harding. After the world war II, United States spontaneously became the leader of the world. Thus the usage of "world" increased, even in the definition of audience. President Licoln used to define his audience as "citizen of United States". After 100 years, president Nixon called his audience "my fellow citizens of the world community". Apparently, instead of the leader of USA, politicians started to veiw themselvs as leaders of the world.
    
    Lastly, modal verbs. Modal verbs can convey emtion of a speech. Take William J. Clinton's speech in 1993 and Barack Obama's in 2009 as comparison. There are huge difference between two speeches with the using of modal verbs "will", "can" and "must". According to M. A. K. Halliday, "will", "can" and "must" are respectly low,  median, high value modal verbs. They can express different emotion with different gesture. In Clinton's speech, the usage of three words are respectly 0.43%, 0.37%, 1.12%, while in Obama's is 0.79%, 0.54%, 0.33%. Consider the historical background, the U.S just won the Gulf war when Clinton won the election, while Obama was facing one of the worst financial crisis.

#Step 0 - Install and load libraries
```{r, message=FALSE, warning=FALSE}
packages.used=c("tm", "wordcloud", "RColorBrewer", 
                "dplyr", "tidytext")

# check packages that need to be installed.
packages.needed=setdiff(packages.used, 
                        intersect(installed.packages()[,1], 
                                  packages.used))
# install additional packages
if(length(packages.needed)>0){
  install.packages(packages.needed, dependencies = TRUE,
                   repos='http://cran.us.r-project.org')
}

library(tm)
library(wordcloud)
library(RColorBrewer)
library(dplyr)
library(tidytext)
```


# Step 1 - Read in the speeches
```{r}
folder.path="../data/inaugurals/"
speeches=list.files(path = folder.path, pattern = "*.txt")
prex.out=substr(speeches, 6, nchar(speeches)-4)

ff.all<-Corpus(DirSource(folder.path))
```

#Step 2 - Text processing


```{r}
ff.all<-tm_map(ff.all, stripWhitespace)
ff.all<-tm_map(ff.all, content_transformer(tolower))
ff.all<-tm_map(ff.all, removeWords, stopwords("english"))
ff.all<-tm_map(ff.all, removeWords, character(0))
ff.all<-tm_map(ff.all, removePunctuation)

tdm.all<-TermDocumentMatrix(ff.all)

tdm.tidy=tidy(tdm.all)

tdm.overall=summarise(group_by(tdm.tidy, term), sum(count))
```



#Step 3 - compute TF-IDF weighted document-term matrices for individual speeches. 


```{r}
dtm <- DocumentTermMatrix(ff.all,
                          control = list(weighting = function(x)
                                             weightTfIdf(x, 
                                                         normalize =FALSE),
                                         stopwords = TRUE))
ff.dtm=tidy(dtm)
```

#Step 4- Interactive visualize important words in individual speeches
```{r, warning=FALSE}
library(shiny)

shinyApp(
    ui = fluidPage(
      fluidRow(style = "padding-bottom: 20px;",
        column(4, selectInput('speech1', 'Speech 1',
                              speeches,
                              selected=speeches[5])),
        column(4, selectInput('speech2', 'Speech 2', speeches,
                              selected=speeches[9])),
        column(4, sliderInput('nwords', 'Number of words', 3,
                               min = 20, max = 200, value=100, step = 20))
      ),
      fluidRow(
        plotOutput('wordclouds', height = "400px")
      )
    ),

    server = function(input, output, session) {

      # Combine the selected variables into a new data frame
      selectedData <- reactive({
        list(dtm.term1=ff.dtm$term[ff.dtm$document==as.character(input$speech1)],
             dtm.count1=ff.dtm$count[ff.dtm$document==as.character(input$speech1)],
             dtm.term2=ff.dtm$term[ff.dtm$document==as.character(input$speech2)],
             dtm.count2=ff.dtm$count[ff.dtm$document==as.character(input$speech2)])
      })

      output$wordclouds <- renderPlot(height = 400, {
        par(mfrow=c(1,2), mar = c(0, 0, 3, 0))
        wordcloud(selectedData()$dtm.term1, 
                  selectedData()$dtm.count1,
              scale=c(4,0.5),
              max.words=input$nwords,
              min.freq=1,
              random.order=FALSE,
              rot.per=0,
              use.r.layout=FALSE,
              random.color=FALSE,
              colors=brewer.pal(10,"Blues"), 
            main=input$speech1)
        wordcloud(selectedData()$dtm.term2, 
                  selectedData()$dtm.count2,
              scale=c(4,0.5),
              max.words=input$nwords,
              min.freq=1,
              random.order=FALSE,
              rot.per=0,
              use.r.layout=FALSE,
              random.color=FALSE,
              colors=brewer.pal(10,"Blues"), 
            main=input$speech2)
      })
    },

    options = list(height = 600)
)
```




# Further readings

+ [Text mining with `tidytext`](http://tidytextmining.com/).
+ [Basic Text Mining in R](https://rstudio-pubs-static.s3.amazonaws.com/31867_8236987cf0a8444e962ccd2aec46d9c3.html)
